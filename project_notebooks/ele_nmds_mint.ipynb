{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import prince"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aggregation and Tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ele_by_region = pd.read_csv(\"ele_by_region_pa.csv\",delimiter=\",\")\n",
    "#ele_by_region.set_index(, inplace=True)\n",
    "ele_by_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_by_region.drop(['Baja','Iran','Namibia','SanFran','Spain','Mongolia','Israel',\n",
    "                   'pI_prb','gc_prob'],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    ">>> famd = prince.FAMD(\n",
    "...     n_components=3,\n",
    "...     n_iter=3,\n",
    "...     copy=True,\n",
    "...     check_input=True,\n",
    "...     engine='auto'\n",
    "... )\n",
    "\n",
    ">>> famd = famd.fit(ele_by_region.drop(['Baja','Iran','Namibia','SanFran','Spain','Mongolia','Israel',\n",
    "                   'pI_prb','gc_prob', \"from\",\"Tn\"],axis='columns'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "famd.column_correlations(ele_by_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_by_region.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca.plot_coordinates(ele_by_region, show_row_labels=True,show_column_labels=True)\n",
    "#tf is a column point\n",
    "plt.savefig(\"henlo.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix =  pd.DataFrame(distance_matrix(ele_by_region.values, ele_by_region.values), index=ele_by_region.index, columns=ele_by_region.index)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import pandas as pd\n",
    "\n",
    ">>> X = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/balloons/adult+stretch.data')\n",
    ">>> X.columns = ['Color', 'Size', 'Action', 'Age', 'Inflated']\n",
    ">>> X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import prince\n",
    ">>> mca = prince.MCA(\n",
    "...     n_components=2,\n",
    "...     n_iter=3,\n",
    "...     copy=True,\n",
    "...     check_input=True,\n",
    "...     engine='auto',\n",
    "...     random_state=42\n",
    "... )\n",
    ">>> mca = mca.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> ax = mca.plot_coordinates(\n",
    "...     X=X,\n",
    "...     ax=None,\n",
    "...     figsize=(6, 6),\n",
    "...     show_row_points=True,\n",
    "...     row_points_size=10,\n",
    "...     show_row_labels=False,\n",
    "...     \n",
    "...     show_column_points=True,\n",
    "...     column_points_size=30,\n",
    "...     show_column_labels=False,\n",
    "...     legend_n_cols=1\n",
    "... )\n",
    "#>>> ax.get_figure().savefig('images/mca_coordinates.svg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in tRNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /media/tian/Backup_Protected/working/halo_pg/ele_nmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locus_elements = {}\n",
    "with open(\"dupes_dict.csv\",'r') as ofh:\n",
    "    for line in ofh:\n",
    "        line = line.strip()\n",
    "        locus_elements[line.split(\",\")[1]] = line.split(\",\")[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_elements = {}\n",
    "with open(\"over_elements.tab\",'r') as ofh:\n",
    "    for line in ofh:\n",
    "        line = line.strip()\n",
    "        if line.split(\",\")[5] in locus_elements.keys():\n",
    "            tagged_elements[line.split(\",\")[0]] = locus_elements[line.split(\",\")[5]]\n",
    "        else:\n",
    "            tagged_elements[line.split(\",\")[0]] = line.split(\",\")[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRNA_positive = []\n",
    "with open(\"trnas_annotate.tab\",'r') as ofh:\n",
    "    for line in ofh:\n",
    "        line = line.strip()\n",
    "        if \"list index\" in line:\n",
    "            continue\n",
    "        tRNA_positive.append(tagged_elements[line.split(\"\\t\")[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(tRNA_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dereplication of second iteration viruses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /media/tian/Backup_Protected/working/halo_pg/ele_nmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saccver = []\n",
    "with open(\"phage_pres_iter2.tab\",'r') as ofh:\n",
    "    for line in ofh:\n",
    "        line = line.strip()\n",
    "        if line.split(\"\\t\")[1] in saccver:\n",
    "            continue\n",
    "        else:\n",
    "            saccver.append(line.split(\"\\t\")[1])\n",
    "            if line.split(\"\\t\")[0][:-2] != line.split(\"\\t\")[1]:\n",
    "                print(line, file=open(\"phage_pres_iter2_derepped.tab\",'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qaccver = []\n",
    "with open(\"phage_pres_iter2_derepped.tab\",'r') as ofh:\n",
    "    for line in ofh:\n",
    "        line = line.strip()\n",
    "        if line.split('\\t')[0] in qaccver:\n",
    "            continue\n",
    "        else:\n",
    "            qaccver.append(line.split(\"\\t\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it2_vH = [\"AMM032;8_18_5_1\",'AMM028;7_0_121_1','AMM036;10_5_160_1','AMM018;5_22_11_1','UG_123;35_3_230_1', 'Ec15;20_3_125_1', 'M5-25-10-8B;28_3_165_1','SD690R;29_4_81_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qaccver = []\n",
    "with open(\"phage_pres_iter2_derepped.tab\",'r') as ofh:\n",
    "    for line in ofh:\n",
    "        line = line.strip()\n",
    "        if line.split('\\t')[0] in it2_vH:\n",
    "            print(line, file=open('virals_only_it2.tab','a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gonna read in the ones i alrady annotated in the first iteration\n",
    "it1 = []\n",
    "with open(\"phage_pres.tab\",'r') as ofh:\n",
    "    for line in ofh:\n",
    "        line = line.strip()\n",
    "        it1.append(line.split(\"\\t\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"virals_only_it2.tab\",'r') as ofh:\n",
    "    for line in ofh:\n",
    "        line = line.strip()\n",
    "        if line.split('\\t')[1] in it1:\n",
    "            continue\n",
    "        else:\n",
    "            print(line, file=open('virals_only_it2_it1gone.tab','a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all of the new seqs\n",
    "new_saccvers_it2 = []\n",
    "with open('virals_only_it2_it1gone.tab','r') as ofh:\n",
    "    for line in ofh:\n",
    "        line = line.strip()\n",
    "        new_saccvers_it2.append(line.split(\"\\t\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd /media/tian/Backup_Protected/working/halo_pg/latest_intersect_cog/ffn/20201109_isolates/fasta_fnas/virus/PROKKA_10292021/clusts/hmmers/hmmerout/hits/cripsr/panaroo/reannotate/single_gene/gffs/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_saccvers_it2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc_locus = {}\n",
    "for seqs in new_saccvers_it2:\n",
    "    with open('gene_data.csv','r') as ofh:\n",
    "        for line in ofh:\n",
    "            line = line.strip()\n",
    "            if seqs.split(\";\")[1] in line:\n",
    "                acc_locus[seqs] = line.split(\",\")[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for real,ltag in acc_locus.items():\n",
    "    with open(\"gene_presence_absence.csv\",'r') as ofh:\n",
    "        for line in ofh:\n",
    "            line = line.strip()\n",
    "            if ltag in line:\n",
    "                print(line.split(\",\")[0] + \"\\t\" +real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing the same for Tn Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /media/tian/Backup_Protected/working/halo_pg/ele_nmds/bacant-db-v2.0/TransposonDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_qaccver = []\n",
    "with open(\"ele_tnDB.tab\",'r') as ofh:\n",
    "    for line in ofh:\n",
    "        line = line.strip()\n",
    "        if line.split(\"\\t\")[0] in tn_qaccver:\n",
    "            continue\n",
    "        else:\n",
    "            tn_qaccver.append(line.split(\"\\t\")[0])\n",
    "            print(line, file=open(\"ele_tnDB_derepped.tab\",'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /media/tian/Backup_Protected/working/halo_pg/latest_intersect_cog/ffn/20201109_isolates/fasta_fnas/virus/PROKKA_10292021/clusts/hmmers/hmmerout/hits/cripsr/panaroo/reannotate/single_gene/gffs/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_locus = {}\n",
    "for seqs in tn_qaccver:\n",
    "    with open('gene_data.csv','r') as ofh:\n",
    "        for line in ofh:\n",
    "            line = line.strip()\n",
    "            if seqs.split(\";\")[1] == line.split(\",\")[2]:\n",
    "                tn_locus[seqs] = line.split(\",\")[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for real,ltag in tn_locus.items():\n",
    "    with open(\"gene_presence_absence.csv\",'r') as ofh:\n",
    "        for line in ofh:\n",
    "            line = line.strip()\n",
    "            if ltag in line:\n",
    "                print(line.split(\",\")[0] + \"\\t\" +real, file=open(\"tn_pa_groups.tab\",'a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Scratch Space\n",
    "1. Transmembrane from TMHMM (deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /media/tian/Backup_Protected/working/halo_pg/latest_intersect_cog/ffn/20201109_isolates/fasta_fnas/virus/PROKKA_10292021/clusts/hmmers/hmmerout/hits/cripsr/panaroo/reannotate/single_gene/gffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "table = pd.read_table(\"all_inserts_explore_cleaned.csv\", comment=\"#\",header=None, converters={})\n",
    "table.columns = ['prime', 'ins_len', 'points', 'path', 'path_distro']\n",
    "\n",
    "table.points = table.points.apply(literal_eval)\n",
    "table.path = table.path.apply(literal_eval)\n",
    "table.path_distro = table.path_distro.apply(literal_eval)\n",
    "ins_fams = {}  # gene fam names along path, only insert\n",
    "ins_distros = {} #gene distributions along path, only contains insert\n",
    "nearest_nayb = {} #same as previous +- 1\n",
    "anchor = {} #the anchor (core gene) for each insert\n",
    "for indy, row in table.iterrows():\n",
    "    \n",
    "    #we want +- 1 gene from ins in distros?\n",
    "    line_dict1 = row[\"path\"]\n",
    "    ins_fams[row[\"prime\"]] = line_dict1[row[\"points\"][0]:row[\"points\"][1]]\n",
    "    ins_distros[row['prime']] = row['path_distro'][row['points'][0]:row[\"points\"][1]]\n",
    "    nearest_nayb[row['prime']] = row['path_distro'][row['points'][0]-1:row[\"points\"][1]+1]\n",
    "    anchor[row['prime']] = row['path'][row['points'][0]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted = {}\n",
    "for k, v in ins_fams.items():\n",
    "    for z in v:\n",
    "        if z not in inverted.keys():\n",
    "            \n",
    "            inverted[z] = k\n",
    "        else:\n",
    "            print(z + \"\\t\" + k, file=open(\"duplicated_shuffled_fams.txt\",'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set(inverted.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_aa_seqs.fasta\",'r') as ofh:\n",
    "    for line in ofh:\n",
    "        line = line.strip()\n",
    "        if \";\" in line:\n",
    "            continue\n",
    "        else:\n",
    "            print(line,file=open(\"aa_seqs_good.fasta\",'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam_membs = {}\n",
    "with open(\"predicted_topologies.3line\",'r') as ofh:\n",
    "    for line in ofh:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\">\"):\n",
    "            fam_membs[line.split(\"|\")[0].split(\".\")[0][1:]] = line.split(\"|\")[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_counter = {}\n",
    "for keys,vals in fam_membs.items():\n",
    "    if inverted[keys] in tm_counter.keys():\n",
    "        tm_counter[inverted[keys]].append(vals)\n",
    "    else:\n",
    "        tm_counter[inverted[keys]] = [vals]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(fam_membs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_counts = {}\n",
    "for keys, values in tm_counter.items():\n",
    "    tm_counts[keys] = dict((Counter(values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys, values in tm_counts.items():\n",
    "    print(keys + \"\\t\" + str(values),file=open(\"tm_annotate.tab\",'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_fams['group_6363|9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
