{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read In Hits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds6_int = pd.read_table('../../deadsea/deadn6.htab', sep='\\t', lineterminator='\\n', skiprows=0)\n",
    "ds6_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for indy,row in ds6_int.iterrows():\n",
    "    if row['hmm _oord_from'] < 25 or row['hmm_coord_to'] == 471:\n",
    "        continue\n",
    "    else:\n",
    "        ds6_int.drop(index=indy, inplace=True)\n",
    "ds6_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds6_int.reset_index(inplace=True, drop=True)\n",
    "ds6_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intein Hit Defragmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# iterrows and refer to previous rows *****\n",
    "# defragments intein hits in htab\n",
    "for indy, row in ds6_int.iterrows():\n",
    "    if row['hmm _oord_from'] == 1:\n",
    "        continue\n",
    "    if row['hmm_coord_to'] == 471:\n",
    "        if row['target_name'] == ds6_int.loc[(int(indy) - 1), 'target_name']:\n",
    "            if row['hmm _oord_from'] > (ds6_int.loc[(int(indy) - 1), 'hmm_coord_to']):\n",
    "                ds6_int.loc[(int(indy) - 1),\n",
    "                            'env_coord_to'] = row['env_coord_to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get rid of C-terms after adding coords\n",
    "index_delete = []\n",
    "for indy, row in ds6_int.iterrows():\n",
    "    if row['hmm _oord_from'] == 1 and row['hmm_coord_to'] == 471:\n",
    "        continue\n",
    "    if row['env_coord_to'] == ds6_int.loc[(int(indy) -1), 'env_coord_to'] and row['target_name'] == ds6_int.loc[(int(indy) -1), 'target_name']:\n",
    "        index_delete.append(indy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds6_int.drop(index=index_delete, inplace=True)\n",
    "ds6_int.reset_index(inplace=True, drop=True)\n",
    "ds6_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Indexer\n",
    "## Intein Seq Get (AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inteins = {}\n",
    "for index, row in ds6_int.iterrows():\n",
    "    if row['target_name'] in inteins.keys():\n",
    "        inteins.setdefault(row['target_name'], []).append(row['env_coord_to'])        \n",
    "        \n",
    "    else:\n",
    "        inteins[row['target_name']] = [ row['env_coord_to']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in fasta\n",
    "faa_fasta = {}\n",
    "with open(\"../../deadsea/deadn6.faa.eol\") as faa_file:\n",
    "    for line in faa_file:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\">\"):\n",
    "            active_sequence_name = line[1:].split(' ')[0]\n",
    "            if active_sequence_name not in faa_fasta.keys():\n",
    "                faa_fasta[active_sequence_name] = \"\"\n",
    "            continue\n",
    "        sequence = line\n",
    "        faa_fasta[active_sequence_name] = sequence\n",
    "\n",
    "faa_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all intein containing genes\n",
    "for prot in inteins.keys():\n",
    "    print('>' + prot + '\\n' + faa_fasta[prot], file=open('intein_genes.fasta', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all invidiual intein seqs\n",
    "for indy, row in ds6_int.iterrows():\n",
    "    start_site = (row['env_coord_from'] - 1)\n",
    "    stop_site = (row['env_coord_to'])\n",
    "    print(\">\" + row['target_name'] + '_' + str(row['dom#']) + '\\n' +\n",
    "          faa_fasta[row['target_name']][start_site:stop_site])  # , file=open('all_int.fasta', 'a') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extein Seq Get (AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# formatting the sites\n",
    "ext_sites = {}\n",
    "for index, row in ds6_int.iterrows():\n",
    "    if row['target_name'] in inteins.keys():\n",
    "        ext_sites.setdefault(row['target_name'], []).append(\n",
    "            row['env_coord_from'])\n",
    "        ext_sites[row['target_name']].append(row['env_coord_to'])\n",
    "    else:\n",
    "        ext_sites[row['target_name']] = [\n",
    "            row['env_coord_from'], row['env_coord_to']]\n",
    "\n",
    "ext_sites\n",
    "# extsites to change for extein grabbbinh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Site Index Slicers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fix_ext_sites = {}\n",
    "for target, vals in ext_sites.items():\n",
    "    dom_num = 0\n",
    "    expression = ''\n",
    "    while dom_num < len(vals):\n",
    "        if dom_num == 0:\n",
    "            expression = expression + \":\" + str(vals[dom_num]) + \",\"\n",
    "            dom_num += 1\n",
    "        if dom_num % 2 != 0:\n",
    "            expression = expression + (str(vals[dom_num] - 1)) + \":\"\n",
    "            dom_num += 1\n",
    "        else:\n",
    "            expression = expression + str(vals[dom_num]) + ','\n",
    "            dom_num += 1\n",
    "    fix_ext_sites[target] = expression.split(',')\n",
    "fix_ext_sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Concat Extein Seqs (AA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get concatenated extein sequences from fix_ext_sites\n",
    "extein_seqs = {}\n",
    "for target, vals in fix_ext_sites.items():\n",
    "    sequence = ''\n",
    "    for pair in vals:\n",
    "        if pair[0] == ':':\n",
    "            first_end = int(pair.split(':')[1])\n",
    "            sequence = sequence + faa_fasta[target][:first_end]\n",
    "        else:\n",
    "            start = int(pair.split(':')[0])\n",
    "\n",
    "            if pair[-1] == ':':\n",
    "                sequence = sequence + faa_fasta[target][start:]\n",
    "            else:\n",
    "                end = int(pair.split(':')[1])\n",
    "                sequence = sequence + faa_fasta[target][start:end]\n",
    "\n",
    "    extein_seqs[target] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target,vals in extein_seqs.items():\n",
    "    print('>' + target + '\\n' + vals )#, file=open('ext_seqs.fasta', 'a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq Get (NT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ffn_fasta = {}\n",
    "with open(\"../../deadsea/deadn6.ffn.eol\") as ffn_file:\n",
    "    for line in ffn_file:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\">\"):\n",
    "            active_sequence_name = line[1:].split(' ')[0]\n",
    "            if active_sequence_name not in ffn_fasta.keys():\n",
    "                ffn_fasta[active_sequence_name] = \"\"\n",
    "            continue\n",
    "        sequence = line\n",
    "        ffn_fasta[active_sequence_name] = sequence\n",
    "\n",
    "ffn_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get concatenated extein sequences from fix_ext_sites\n",
    "nt_extein_seqs = {}\n",
    "for target, vals in fix_ext_sites.items():\n",
    "    sequence = ''\n",
    "    for pair in vals:\n",
    "        if pair[0] == ':':\n",
    "            first_end = int(pair.split(':')[1])\n",
    "            sequence = sequence + ffn_fasta[target][:(first_end*3)]\n",
    "        else:\n",
    "            start = int(pair.split(':')[0])\n",
    "\n",
    "            if pair[-1] == ':':\n",
    "                sequence = sequence + ffn_fasta[target][(start*3):]\n",
    "            else:\n",
    "                end = int(pair.split(':')[1])\n",
    "                sequence = sequence + ffn_fasta[target][(3*start):(3*end)]\n",
    "\n",
    "    nt_extein_seqs[target] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, seqs in nt_extein_seqs.items():\n",
    "    print('>' + target + '_ext_full\\n' +\n",
    "          ffn_fasta[target], file=open('../../deadsea/seq_out/nt_full_ext_seqs.fasta', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all invidiual NT intein seqs\n",
    "for indy, row in ds6_int.iterrows():\n",
    "    start_site = (row['env_coord_from'] - 1)\n",
    "    stop_site = (row['env_coord_to'])\n",
    "    print(\">\" + row['target_name'] + '_' + str(row['dom#']) + '\\n' + ffn_fasta[row['target_name']]\n",
    "          [(start_site*3):(stop_site*3)], file=open('../../deadsea/seq_out/nt_int.fasta', 'a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homing Endonuclease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in blocked file, into a list.uniq(), if present in list and inteins dict then its a full\n",
    "full_inteins = []\n",
    "for line in open('../../deadsea/seq_out/hensearch/all_int_low.blocked').readlines():\n",
    "    line = line.split()\n",
    "    full_inteins.append(line[0])\n",
    "full_uniqs=  list(set(full_inteins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds6_int['int_size'] = ''\n",
    "for indy, row in ds6_int.iterrows():\n",
    "    if (row['target_name'] + '_' + str(row['dom#'])) in full_uniqs:\n",
    "        ds6_int.loc[indy, 'int_size'] = 'full'\n",
    "    else:\n",
    "        ds6_int.loc[indy, 'int_size'] = 'mini'\n",
    "ds6_int        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multi_hen_dict = {}\n",
    "for indy, row in ds6_int.iterrows():\n",
    "    if row['target_name'] in multi_hen_dict.keys():\n",
    "        multi_hen_dict.setdefault(\n",
    "            row['target_name'], []).append(row['int_size'])\n",
    "\n",
    "    else:\n",
    "        multi_hen_dict[row['target_name']] = [row['int_size']]\n",
    "multi_hen_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uri_multi int (later for mini inteins i think)\n",
    "ds_gene_count = len(inteins)  # number of total genes with 1+ inteins\n",
    "# multi_hens = 0 #skip but number of hens per multi genes\n",
    "multi_inteins = 0  # multiple inteins total (count of inteins)\n",
    "# single intein in gene. if only 1 target_name (count of gene/inteins)\n",
    "single = 0\n",
    "# single intein in gene w/HEN. (count of inteins) if only 1 target name and full\n",
    "single_hen = 0\n",
    "# genes with multiple inteins (count of genes). if multiple target_names\n",
    "multiple_genes = 0\n",
    "# multiple inteins with hen (count of inteins). if multiple target_names, and full\n",
    "multiple_hen = 0\n",
    "# multiple_hen/multi_inteins = % of multiple inteins with HEN\n",
    "\n",
    "for target, vals in multi_hen_dict.items():\n",
    "    if len(vals) == 1:\n",
    "        single += 1\n",
    "        if vals[0] == 'full':\n",
    "            single_hen += 1\n",
    "    if len(vals) > 1:\n",
    "\n",
    "        multiple_genes += 1\n",
    "        multi_inteins += len(vals)\n",
    "        for size in vals:\n",
    "            if size == 'full':\n",
    "                multiple_hen += 1\n",
    "# need to change the flat values to be extensible\n",
    "print('Dead Sea\\nGenes with multiple inteins:\\t' + str(multiple_genes) + ' (' + str(ds_gene_count) + ')\\t' + str(multiple_genes/ds_gene_count) +\n",
    "      '\\nMulti-Inteins with HEN:\\t\\t' + str(multiple_hen) + '\\t\\t' + str(multiple_hen/multi_inteins) +\n",
    "      '\\nSingle-Inteins with HEN:\\t' + str(single_hen) + '\\t\\t' + str(single_hen/single) + \n",
    "     '\\nTotal full inteins:\\t\\t' + str(single_hen + multiple_hen) + ' (' + str(single + multi_inteins) + ')\\t' + str((single_hen+multiple_hen)/(single + multi_inteins)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NR mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_info = pd.read_csv('../../deadsea/exteinbackground.tab', sep='\\t', header=None, usecols=[0, 3])\n",
    "nr_info.columns = ['target_name', 'title']\n",
    "nr_info.drop_duplicates(subset='target_name', inplace=True)\n",
    "ds6_int_anno = ds6_int.merge(nr_info, how='left', left_on='target_name', right_on='target_name')\n",
    "ds6_int_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds6_int_anno['organism'] = ds6_int_anno['title'].map(lambda x: re.search(r'\\[.+?(?=\\])|$', str(x)).group())\n",
    "ds6_int_anno['gene'] = ds6_int_anno['title'].map(lambda x: re.search(r'^.+?(?=\\[)|$', str(x)).group())\n",
    "ds6_int_anno.drop(['title'], axis=1, inplace=True)\n",
    "ds6_int_anno['organism'] = ds6_int_anno['organism'].map(lambda x: x.lstrip('['))\n",
    "ds6_int_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds6_int_anno.organism.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chalkboard Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_ext_sites['PROKKA_35178'] #35178 has 5 reads over IIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in SAM\n",
    "After you convert the bam map file using Samtools view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get samtools view \"regions\"\n",
    "for target, sites in ext_sites.items():\n",
    "    site = 0\n",
    "    anchor = 0\n",
    "    if len(sites) > 2:\n",
    "        while site < (len(sites) -1):\n",
    "        \n",
    "            if site == 0:\n",
    "                anchor = anchor +  (sites[site] *3)\n",
    "                print(target + \"_ext:\" + str(anchor-3) + '-' + str(anchor+3) )\n",
    "                site += 2\n",
    "            if site % 2 == 0 and site != 0:\n",
    "                anchor = anchor + ((sites[site] - sites[site-1]) *3) \n",
    "                print(target + \"_ext:\"+ str(anchor-3) + '-' + str(anchor+3))\n",
    "                site +=2\n",
    "    else:\n",
    "        anchor = anchor +  (sites[site] *3)\n",
    "        print(target + \"_ext:\" + str(anchor-3) + '-' + str(anchor+3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#post region call\n",
    "iis_sam = pd.read_table('../../deadsea/seq_out/iis/testview.sam',\n",
    "                        usecols=[0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13], header=None, sep='\\t')\n",
    "iis_sam.columns = ['read', 'bits', 'target_name',\n",
    "                   'pos', 'mapq', 'cigar', 'mate_target', 'mpos', 'tlen' ,  'nm', 'as', 'xs']\n",
    "iis_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iis_counter = {}\n",
    "iis_lens = {}\n",
    "number  = 0\n",
    "for index, row in iis_sam.iterrows():\n",
    "    if '3D' in row['cigar']:\n",
    "        \n",
    "        if row['target_name'][:-4] in iis_counter.keys():\n",
    "            iis_counter.setdefault(row['target_name'][:-4], []).append(row['cigar'])\n",
    "        else:\n",
    "            iis_counter[row['target_name'][:-4]] = [row['cigar']]\n",
    "for target, vals in iis_counter.items():\n",
    "    iis_lens[target] = len(vals)\n",
    "iis_lens\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds6_int_man = pd.read_csv('../../deadsea/ds6_int_anno.tab', header=None, sep='\\t')\n",
    "ds6_int_man.columns = ['target_name', 'accession', 'tlen', 'query_name', 'accession.1', 'qlen',\n",
    "       'full_sequence_E-value', 'full_sequence_score', 'full_sequence_bias',\n",
    "       'dom#', 'ndom', 'c-Evalue', 'i-Evalue', 'score', 'bias',\n",
    "       'hmm _oord_from', 'hmm_coord_to', 'ali_coord_from', 'ali_coord_to',\n",
    "       'env_coord_from', 'env_coord_to', 'acc', 'man_desc', 'description_of_target',\n",
    "       'int_size', 'species', 'gene']\n",
    "ds6_int_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds6_int_man = pd.read_csv('../../deadsea/ds6_int_anno.tab', header=None, sep='\\t')\n",
    "ds6_int_man.columns = ['target_name', 'accession', 'tlen', 'query_name', 'accession.1', 'qlen',\n",
    "       'full_sequence_E-value', 'full_sequence_score', 'full_sequence_bias',\n",
    "       'dom#', 'ndom', 'c-Evalue', 'i-Evalue', 'score', 'bias',\n",
    "       'hmm _oord_from', 'hmm_coord_to', 'ali_coord_from', 'ali_coord_to',\n",
    "       'env_coord_from', 'env_coord_to', 'acc', 'man_desc', 'description_of_target',\n",
    "       'int_size', 'species', 'gene']\n",
    "ds6_int_man['allele'] = ''\n",
    "for index, row in ds6_int_man.iterrows():\n",
    "    abridged = row['man_desc'].split('_')[0]\n",
    "    ds6_int_man.loc[index, 'allele'] = abridged\n",
    "ds6_int_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extein_cat_seqs = {}\n",
    "for index, row in ds6_int_man.iterrows():\n",
    "    if row['allele'] in extein_cat_seqs.keys():\n",
    "           extein_cat_seqs.setdefault(row['allele'], []).append(row['target_name'])\n",
    "    else:\n",
    "        extein_cat_seqs[row['allele']] = [row['target_name']]\n",
    "extein_cat_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniq_targets ={}\n",
    "for allele, targets in extein_cat_seqs.items():\n",
    "    uniq_exts =  list(set(targets))\n",
    "    uniq_targets[allele] = uniq_exts\n",
    "for allele, targets in uniq_targets.items():\n",
    "    for seq in targets:\n",
    "        print('>' + seq + '\\n' + extein_seqs[seq], file=open('../../deadsea/seq_out/' + allele + '.ext', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds6_int_man['domain'] = ''\n",
    "ds6_int_man.set_value(146, 'species', 'unclass')\n",
    "ds6_int_man.set_value(142, 'species', 'unclass')\n",
    "ds6_int_man.set_value(152, 'species', 'unclass')\n",
    "\n",
    "for index, row in ds6_int_man.iterrows():\n",
    "    if 'virus' in row['species'] or 'phage' in row['species']:\n",
    "        ds6_int_man.set_value(index, 'domain', 'virus')\n",
    "    elif 'Nealsonbacteria' in row['species'] or 'Sinorhizobium' in row['species']:\n",
    "        ds6_int_man.set_value(index, 'domain', 'bacteria')\n",
    "    elif row['species'] == 'unclass':\n",
    "        ds6_int_man.set_value(index, \"domain\", 'unclass')\n",
    "    else:\n",
    "        ds6_int_man.set_value(index, 'domain', 'archaea')\n",
    "ds6_int_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#typo in manual curation fixed\n",
    "ds6_int_man.loc[136, 'man_desc'] = 'hypo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in ds6_int_man.iterrows():\n",
    "    if 'hypo' in row['allele']:\n",
    "        ds6_int_man.loc[index, 'allele'] = 'hypo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds6_domains = ds6_int_man.groupby('domain').count()\n",
    "ds6_domain_plotable = dict(ds6_domains.target_name)\n",
    "ds6_alleles = ds6_int_man.groupby('allele').count()\n",
    "ds6_alleles_plotable = dict(ds6_alleles.target_name)\n",
    "ds6_alleles_plotable\n",
    "ds6_alleles_spec = ds6_int_man.groupby('int_spec').count()\n",
    "ds6_alleles_spec_plotable = dict(ds6_alleles_spec.target_name)\n",
    "ds6_alleles_spec_plotable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds6_int_man['int_spec'] = \"\"\n",
    "for index, row in ds6_int_man.iterrows():\n",
    "    abridged = row['man_desc'].split(',')[0]\n",
    "    ds6_int_man.loc[index, 'int_spec'] = abridged\n",
    "ds6_int_man.int_spec.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atlit 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "at22_int = pd.read_table('../../atlit/at22.htab', sep='\\t', lineterminator='\\n', skiprows=0)\n",
    "for indy,row in at22_int.iterrows():\n",
    "    if row['hmm _oord_from'] < 25 or row['hmm_coord_to'] == 471:\n",
    "        continue\n",
    "    else:\n",
    "        at22_int.drop(index=indy, inplace=True)\n",
    "at22_int.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indy, row in at22_int.iterrows():\n",
    "    if row['hmm _oord_from'] == 1:\n",
    "        continue\n",
    "    if row['hmm_coord_to'] == 471:\n",
    "        if row['target_name'] == at22_int.loc[(int(indy) - 1), 'target_name']:\n",
    "            if row['hmm _oord_from'] > (at22_int.loc[(int(indy) - 1), 'hmm_coord_to']):\n",
    "                at22_int.loc[(int(indy) - 1),\n",
    "                            'env_coord_to'] = row['env_coord_to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_index_delete = []\n",
    "for indy, row in at22_int.iterrows():\n",
    "    if row['hmm _oord_from'] == 1 and row['hmm_coord_to'] == 471:\n",
    "        continue\n",
    "    if indy == 0:\n",
    "        continue \n",
    "    if row['env_coord_to'] == at22_int.loc[(int(indy) - 1), 'env_coord_to'] and row['target_name'] == at22_int.loc[(int(indy) - 1), 'target_name']:\n",
    "        at_index_delete.append(indy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at22_int.drop(index=at_index_delete, inplace=True)\n",
    "at22_int.reset_index(inplace=True, drop=True)\n",
    "at22_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_inteins = {}\n",
    "for index, row in at22_int.iterrows():\n",
    "    if row['target_name'] in at_inteins.keys():\n",
    "        at_inteins.setdefault(row['target_name'], []).append(row['env_coord_to'])        \n",
    "        \n",
    "    else:\n",
    "        at_inteins[row['target_name']] = [ row['env_coord_to']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in fasta\n",
    "at_faa_fasta = {}\n",
    "with open(\"../../atlit/at22.faa.eol\") as at_faa_file:\n",
    "    for line in at_faa_file:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\">\"):\n",
    "            active_sequence_name = line[1:].split(' ')[0]\n",
    "            if active_sequence_name not in at_faa_fasta.keys():\n",
    "                at_faa_fasta[active_sequence_name] = \"\"\n",
    "            continue\n",
    "        sequence = line\n",
    "        at_faa_fasta[active_sequence_name] = sequence\n",
    "\n",
    "at_faa_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prot in at_inteins.keys():\n",
    "    print('>' + prot + '\\n' + at_faa_fasta[prot]) # file=open('../../atlit/intein_cds.fasta', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indy, row in at22_int.iterrows():\n",
    "    start_site = (row['env_coord_from'] - 1)\n",
    "    stop_site = (row['env_coord_to'])\n",
    "    print(\">\" + row['target_name'] + '_' + str(row['dom#']) + '\\n' +\n",
    "          at_faa_fasta[row['target_name']][start_site:stop_site] )#, file=open('../../atlit/all_int.fasta', 'a') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at22_int.loc[at22_int['target_name'] == 'PROKKA_18003']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# formatting the sites\n",
    "at_ext_sites = {}\n",
    "for index, row in at22_int.iterrows():\n",
    "    if row['target_name'] in at_inteins.keys():\n",
    "        at_ext_sites.setdefault(row['target_name'], []).append(\n",
    "            row['env_coord_from'])\n",
    "        at_ext_sites[row['target_name']].append(row['env_coord_to'])\n",
    "    else:\n",
    "        at_ext_sites[row['target_name']] = [\n",
    "            row['env_coord_from'], row['env_coord_to']]\n",
    "\n",
    "at_ext_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "at_fix_ext_sites = {}\n",
    "for target, vals in at_ext_sites.items():\n",
    "    dom_num = 0\n",
    "    expression = ''\n",
    "    while dom_num < len(vals):\n",
    "        if dom_num == 0:\n",
    "            expression = expression + \":\" + str(vals[dom_num]) + \",\"\n",
    "            dom_num += 1\n",
    "        if dom_num % 2 != 0:\n",
    "            expression = expression + (str(vals[dom_num] - 1)) + \":\"\n",
    "            dom_num += 1\n",
    "        else:\n",
    "            expression = expression + str(vals[dom_num]) + ','\n",
    "            dom_num += 1\n",
    "    at_fix_ext_sites[target] = expression.split(',')\n",
    "at_fix_ext_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get concatenated extein sequences from fix_ext_sites\n",
    "at_extein_seqs = {}\n",
    "for target, vals in at_fix_ext_sites.items():\n",
    "    sequence = ''\n",
    "    for pair in vals:\n",
    "        if pair[0] == ':':\n",
    "            first_end = int(pair.split(':')[1])\n",
    "            sequence = sequence + at_faa_fasta[target][:first_end]\n",
    "        else:\n",
    "            start = int(pair.split(':')[0])\n",
    "\n",
    "            if pair[-1] == ':':\n",
    "                sequence = sequence + at_faa_fasta[target][start:]\n",
    "            else:\n",
    "                end = int(pair.split(':')[1])\n",
    "                sequence = sequence + at_faa_fasta[target][start:end]\n",
    "\n",
    "    at_extein_seqs[target] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target,vals in at_extein_seqs.items():\n",
    "    print('>' + target + '\\n' + vals, file=open('../../atlit/ext_seqs.fasta', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "at_ffn_fasta = {}\n",
    "with open(\"../../atlit/at22.ffn.eol\") as at_ffn_file:\n",
    "    for line in at_ffn_file:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\">\"):\n",
    "            active_sequence_name = line[1:].split(' ')[0]\n",
    "            if active_sequence_name not in at_ffn_fasta.keys():\n",
    "                at_ffn_fasta[active_sequence_name] = \"\"\n",
    "            continue\n",
    "        sequence = line\n",
    "        at_ffn_fasta[active_sequence_name] = sequence\n",
    "\n",
    "at_ffn_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get concatenated extein sequences from fix_ext_sites\n",
    "at_nt_extein_seqs = {}\n",
    "for target, vals in at_fix_ext_sites.items():\n",
    "    sequence = ''\n",
    "    for pair in vals:\n",
    "        if pair[0] == ':':\n",
    "            first_end = int(pair.split(':')[1])\n",
    "            sequence = sequence + at_ffn_fasta[target][:(first_end*3)]\n",
    "        else:\n",
    "            start = int(pair.split(':')[0])\n",
    "\n",
    "            if pair[-1] == ':':\n",
    "                sequence = sequence + at_ffn_fasta[target][(start*3):]\n",
    "            else:\n",
    "                end = int(pair.split(':')[1])\n",
    "                sequence = sequence + at_ffn_fasta[target][(3*start):(3*end)]\n",
    "\n",
    "    at_nt_extein_seqs[target] = sequence\n",
    "for target, seqs in at_nt_extein_seqs.items():\n",
    "    print('>' + target + '_ext_full\\n' +\n",
    "          at_ffn_fasta[target], file=open('../../atlit/nt_full_ext_seqs.fasta', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, seqs in at_nt_extein_seqs.items():\n",
    "    print('>' + target + '_ext\\n' +\n",
    "          seqs, file=open('../../atlit/nt_ext_seqs.fasta', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all invidiual NT intein seqs\n",
    "for indy, row in at22_int.iterrows():\n",
    "    start_site = (row['env_coord_from'] - 1)\n",
    "    stop_site = (row['env_coord_to'])\n",
    "    print(\">\" + row['target_name'] + '_' + str(row['dom#']) + '\\n' + at_ffn_fasta[row['target_name']]\n",
    "          [(start_site*3):(stop_site*3)], file=open('../../atlit/nt_int.fasta', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_full_inteins = []\n",
    "for line in open('../../atlit/hensearch/at22.blocked').readlines():\n",
    "    line = line.split()\n",
    "    at_full_inteins.append(line[0])\n",
    "at_full_uniqs=  list(set(at_full_inteins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at22_int['int_size'] = ''\n",
    "for indy, row in at22_int.iterrows():\n",
    "    if (row['target_name'] + '_' + str(row['dom#'])) in at_full_uniqs:\n",
    "        at22_int.loc[indy, 'int_size'] = 'full'\n",
    "    else:\n",
    "        at22_int.loc[indy, 'int_size'] = 'mini'\n",
    "at22_int        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_multi_hen_dict = {}\n",
    "for indy, row in at22_int.iterrows():\n",
    "    if row['target_name'] in at_multi_hen_dict.keys():\n",
    "        at_multi_hen_dict.setdefault(\n",
    "            row['target_name'], []).append(row['int_size'])\n",
    "\n",
    "    else:\n",
    "        at_multi_hen_dict[row['target_name']] = [row['int_size']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uri_multi int (later for mini inteins i think)\n",
    "at_ds_gene_count = len(at_inteins)  # number of total genes with 1+ inteins\n",
    "# multi_hens = 0 #skip but number of hens per multi genes\n",
    "at_multi_inteins = 0  # multiple inteins total (count of inteins)\n",
    "# single intein in gene. if only 1 target_name (count of gene/inteins)\n",
    "at_single = 0\n",
    "# single intein in gene w/HEN. (count of inteins) if only 1 target name and full\n",
    "at_single_hen = 0\n",
    "# genes with multiple inteins (count of genes). if multiple target_names\n",
    "at_multiple_genes = 0\n",
    "# multiple inteins with hen (count of inteins). if multiple target_names, and full\n",
    "at_multiple_hen = 0\n",
    "# multiple_hen/multi_inteins = % of multiple inteins with HEN\n",
    "\n",
    "for target, vals in at_multi_hen_dict.items():\n",
    "    if len(vals) == 1:\n",
    "        at_single += 1\n",
    "        if vals[0] == 'full':\n",
    "            at_single_hen += 1\n",
    "    if len(vals) > 1:\n",
    "\n",
    "        at_multiple_genes += 1\n",
    "        at_multi_inteins += len(vals)\n",
    "        for size in vals:\n",
    "            if size == 'full':\n",
    "                at_multiple_hen += 1\n",
    "# need to change the flat values to be extensible\n",
    "print('Atlit Coast\\nGenes with multiple inteins:\\t' + str(at_multiple_genes) + ' (' + str(at_ds_gene_count) + ')\\t' + str(at_multiple_genes/at_ds_gene_count) +\n",
    "      '\\nMulti-Inteins with HEN:\\t\\t' + str(at_multiple_hen) + '\\t\\t' + str(at_multiple_hen/at_multi_inteins) +\n",
    "      '\\nSingle-Inteins with HEN:\\t' + str(at_single_hen) + '\\t\\t' + str(at_single_hen/at_single) + \n",
    "     '\\nTotal full inteins:\\t\\t' + str(at_single_hen + at_multiple_hen) + ' (' + str(at_single + at_multi_inteins) + ')\\t' + str((at_single_hen+at_multiple_hen)/(at_single + at_multi_inteins)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_nr_info = pd.read_csv('../../atlit/nr/at_exteinbackground.tab', sep='\\t', header=None, usecols=[0, 3])\n",
    "at_nr_info.columns = ['target_name', 'title']\n",
    "at_nr_info.drop_duplicates(subset='target_name', inplace=True)\n",
    "at_int_anno = at22_int.merge(at_nr_info, how='left', left_on='target_name', right_on='target_name')\n",
    "at_int_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_int_anno['organism'] = at_int_anno['title'].map(lambda x: re.search(r'\\[.+?(?=\\])|$', str(x)).group())\n",
    "at_int_anno['gene'] = at_int_anno['title'].map(lambda x: re.search(r'^.+?(?=\\[)|$', str(x)).group())\n",
    "at_int_anno.drop(['title'], axis=1, inplace=True)\n",
    "at_int_anno['organism'] = at_int_anno['organism'].map(lambda x: x.lstrip('['))\n",
    "at_int_anno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlit Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for target, sites in at_ext_sites.items():\n",
    "    site = 0\n",
    "    anchor = 0\n",
    "    if len(sites) > 2:\n",
    "        while site < (len(sites) -1):\n",
    "        \n",
    "            if site == 0:\n",
    "                anchor = anchor +  (sites[site] *3)\n",
    "                print(target + \"_ext:\" + str(anchor-3) + '-' + str(anchor+3) )\n",
    "                site += 2\n",
    "            if site % 2 == 0 and site != 0:\n",
    "                anchor = anchor + ((sites[site] - sites[site-1]) *3) \n",
    "                print(target + \"_ext:\"+ str(anchor-3) + '-' + str(anchor+3))\n",
    "                site +=2\n",
    "    else:\n",
    "        anchor = anchor +  (sites[site] *3)\n",
    "        print(target + \"_ext:\" + str(anchor-3) + '-' + str(anchor+3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "at_iis_sam = pd.read_table('../../atlit/iis/testview_combo.sam',\n",
    "                        usecols=[0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13], header=None, sep='\\t')\n",
    "at_iis_sam.columns = ['read', 'bits', 'target_name',\n",
    "                   'pos', 'mapq', 'cigar', 'mate_target', 'mpos', 'tlen' ,  'nm', 'as', 'xs']\n",
    "at_iis_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_iis_counter = {}\n",
    "at_iis_lens = {}\n",
    "#number  = 0\n",
    "for index, row in at_iis_sam.iterrows():\n",
    "    if '3D' in row['cigar']:\n",
    "        \n",
    "        if row['target_name'][:-4] in at_iis_counter.keys():\n",
    "            at_iis_counter.setdefault(row['target_name'][:-4], []).append(row['cigar'])\n",
    "        else:\n",
    "            at_iis_counter[row['target_name'][:-4]] = [row['cigar']]\n",
    "for target, vals in at_iis_counter.items():\n",
    "    at_iis_lens[target] = len(vals)\n",
    "at_iis_lens\n",
    "\n",
    "#40088 artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_int_man = pd.read_csv('../../atlit/at_int_anno', sep='\\t')\n",
    "at_int_man.columns = ['target_name', 'accession', 'tlen', 'query_name', 'accession.1', 'qlen',\n",
    "       'full_sequence_E-value', 'full_sequence_score', 'full_sequence_bias',\n",
    "       'dom#', 'ndom', 'c-Evalue', 'i-Evalue', 'score', 'bias',\n",
    "       'hmm _oord_from', 'hmm_coord_to', 'ali_coord_from', 'ali_coord_to',\n",
    "       'env_coord_from', 'env_coord_to', 'acc', 'man_desc', 'description_of_target',\n",
    "       'int_size', 'species', 'gene']\n",
    "at_int_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_int_man['allele'] = ''\n",
    "for index, row in at_int_man.iterrows():\n",
    "    abridged = row['man_desc'].split('_')[0]\n",
    "    at_int_man.loc[index, 'allele'] = abridged\n",
    "at_int_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_extein_cat_seqs = {}\n",
    "for index, row in at_int_man.iterrows():\n",
    "    if row['allele'] in at_extein_cat_seqs.keys():\n",
    "           at_extein_cat_seqs.setdefault(row['allele'], []).append(row['target_name'])\n",
    "    else:\n",
    "        at_extein_cat_seqs[row['allele']] = [row['target_name']]\n",
    "at_extein_cat_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_uniq_targets ={}\n",
    "for allele, targets in at_extein_cat_seqs.items():\n",
    "    uniq_exts =  list(set(targets))\n",
    "    at_uniq_targets[allele] = uniq_exts\n",
    "for allele, targets in at_uniq_targets.items():\n",
    "    for seq in targets:\n",
    "        print('>' + seq + '\\n' + at_extein_seqs[seq], file=open('../../atlit/manual/' + allele + '.ext', 'a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl30_int = pd.read_table('dl30.htab', sep='\\t', lineterminator='\\n', skiprows=0)\n",
    "for indy,row in dl30_int.iterrows():\n",
    "    if row['hmm _oord_from'] < 25 or row['hmm_coord_to'] >= 469:\n",
    "        continue\n",
    "    else:\n",
    "        dl30_int.drop(index=indy, inplace=True)\n",
    "dl30_int.reset_index(inplace=True, drop=True)\n",
    "dl30_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indy, row in dl30_int.iterrows():\n",
    "    if row['hmm _oord_from'] == 1:\n",
    "        continue\n",
    "    if row['hmm_coord_to'] >= 469:\n",
    "        if row['target_name'] == dl30_int.loc[(int(indy) - 1), 'target_name']:\n",
    "            if row['hmm _oord_from'] > (dl30_int.loc[(int(indy) - 1), 'hmm_coord_to']):\n",
    "                dl30_int.loc[(int(indy) - 1),\n",
    "                            'env_coord_to'] = row['env_coord_to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_index_delete = []\n",
    "for indy, row in dl30_int.iterrows():\n",
    "    if row['hmm _oord_from'] == 1 and row['hmm_coord_to'] >= 469:\n",
    "        continue\n",
    "    if indy == 0:\n",
    "        continue \n",
    "    if row['env_coord_to'] == dl30_int.loc[(int(indy) - 1), 'env_coord_to'] and row['target_name'] == dl30_int.loc[(int(indy) - 1), 'target_name']:\n",
    "        dl_index_delete.append(indy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl30_int.drop(index=dl_index_delete, inplace=True)\n",
    "dl30_int.reset_index(inplace=True, drop=True)\n",
    "dl30_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_faa_fasta = {}\n",
    "with open(\"dl30.faa.eol\") as dl_faa_file:\n",
    "    for line in dl_faa_file:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\">\"):\n",
    "            active_sequence_name = line[1:].split(' ')[0]\n",
    "            if active_sequence_name not in dl_faa_fasta.keys():\n",
    "                dl_faa_fasta[active_sequence_name] = \"\"\n",
    "            continue\n",
    "        sequence = line\n",
    "        dl_faa_fasta[active_sequence_name] = sequence\n",
    "\n",
    "#dl_faa_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl_int_man.loc[10, 'env_coord_to'] = 217\n",
    "dl_int_man.to_csv('../mix_dl_int_man.tab', index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_inteins = {}\n",
    "for index, row in dl_int_man.iterrows():\n",
    "    if row['target_name'] in dl_inteins.keys():\n",
    "        dl_inteins.setdefault(row['target_name'], []).append(row['env_coord_to'])        \n",
    "        \n",
    "    else:\n",
    "        dl_inteins[row['target_name']] = [ row['env_coord_to']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_inteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prot in dl_inteins.keys():\n",
    "    print('>' + prot + '\\n' + dl_faa_fasta[prot], file=open('intein_cds.fasta', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indy, row in dl_int_man.iterrows():\n",
    "    start_site = (row['env_coord_from'] - 1)\n",
    "    stop_site = (row['env_coord_to'])\n",
    "    print(\">\" + row['target_name'] + '_' + str(row['dom#']) + '\\n' +\n",
    "          dl_faa_fasta[row['target_name']][start_site:stop_site], file=open('all_int_2.fasta', 'a') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_ext_sites = {}\n",
    "for index, row in dl_int_man.iterrows():\n",
    "    if row['target_name'] in dl_inteins.keys():\n",
    "        dl_ext_sites.setdefault(row['target_name'], []).append(\n",
    "            row['env_coord_from'])\n",
    "        dl_ext_sites[row['target_name']].append(row['env_coord_to'])\n",
    "    else:\n",
    "        dl_ext_sites[row['target_name']] = [\n",
    "            row['env_coord_from'], row['env_coord_to']]\n",
    "\n",
    "dl_ext_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_fix_ext_sites = {}\n",
    "for target, vals in dl_ext_sites.items():\n",
    "    dom_num = 0\n",
    "    expression = ''\n",
    "    while dom_num < len(vals):\n",
    "        if dom_num == 0:\n",
    "            expression = expression + \":\" + str(vals[dom_num]) + \",\"\n",
    "            dom_num += 1\n",
    "        if dom_num % 2 != 0:\n",
    "            expression = expression + (str(vals[dom_num] - 1)) + \":\"\n",
    "            dom_num += 1\n",
    "        else:\n",
    "            expression = expression + str(vals[dom_num]) + ','\n",
    "            dom_num += 1\n",
    "    dl_fix_ext_sites[target] = expression.split(',')\n",
    "dl_fix_ext_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get concatenated extein sequences from fix_ext_sites\n",
    "dl_extein_seqs = {}\n",
    "for target, vals in dl_fix_ext_sites.items():\n",
    "    sequence = ''\n",
    "    for pair in vals:\n",
    "        if pair[0] == ':':\n",
    "            first_end = int(pair.split(':')[1])\n",
    "            sequence = sequence + dl_faa_fasta[target][:first_end]\n",
    "        else:\n",
    "            start = int(pair.split(':')[0])\n",
    "\n",
    "            if pair[-1] == ':':\n",
    "                sequence = sequence + dl_faa_fasta[target][start:]\n",
    "            else:\n",
    "                end = int(pair.split(':')[1])\n",
    "                sequence = sequence + dl_faa_fasta[target][start:end]\n",
    "\n",
    "    dl_extein_seqs[target] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target,vals in dl_extein_seqs.items():\n",
    "    print('>' + target + '\\n' + vals, file=open('ext_seqs.fasta', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_ffn_fasta = {}\n",
    "with open(\"dl30.ffn.eol\") as dl_ffn_file:\n",
    "    for line in dl_ffn_file:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\">\"):\n",
    "            active_sequence_name = line[1:].split(' ')[0]\n",
    "            if active_sequence_name not in dl_ffn_fasta.keys():\n",
    "                dl_ffn_fasta[active_sequence_name] = \"\"\n",
    "            continue\n",
    "        sequence = line\n",
    "        dl_ffn_fasta[active_sequence_name] = sequence\n",
    "\n",
    "dl_ffn_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_fix_ext_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get concatenated extein sequences from fix_ext_sites\n",
    "dl_nt_extein_seqs = {}\n",
    "for target, vals in dl_fix_ext_sites.items():\n",
    "    sequence = ''\n",
    "    for pair in vals:\n",
    "        if pair[0] == ':':\n",
    "            first_end = int(pair.split(':')[1])\n",
    "            sequence = sequence + dl_ffn_fasta[target][:(first_end*3)]\n",
    "        else:\n",
    "            start = int(pair.split(':')[0])\n",
    "\n",
    "            if pair[-1] == ':':\n",
    "                sequence = sequence + dl_ffn_fasta[target][(start*3):]\n",
    "            else:\n",
    "                end = int(pair.split(':')[1])\n",
    "                sequence = sequence + dl_ffn_fasta[target][(3*start):(3*end)]\n",
    "\n",
    "    dl_nt_extein_seqs[target] = sequence\n",
    "#for target, seqs in dl_nt_extein_seqs.items():\n",
    " #   print('>' + target + '_ext_full\\n' +\n",
    "  #        dl_ffn_fasta[target], file=open('nt_full_ext_seqs.fasta', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_nt_extein_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, seqs in dl_nt_extein_seqs.items():\n",
    "    print('>' + target + '_ext\\n' +\n",
    "          seqs, file=open('nt_ext_seqs_2.fasta', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all invidiual NT intein seqs\n",
    "for indy, row in dl_int_man.iterrows():\n",
    "    start_site = (row['env_coord_from'] - 1)\n",
    "    stop_site = (row['env_coord_to'])\n",
    "    print(\">\" + row['target_name'] + '_' + str(row['dom#']) + '\\n' + dl_ffn_fasta[row['target_name']]\n",
    "          [(start_site*3):(stop_site*3)], file=open('nt_int_2.fasta', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_int_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_full_inteins = []\n",
    "for line in open('hensearch/dl30.blocked').readlines():\n",
    "    line = line.split()\n",
    "    dl_full_inteins.append(line[0])\n",
    "dl_full_uniqs=  list(set(dl_full_inteins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl30_int['int_size'] = ''\n",
    "for indy, row in dl30_int.iterrows():\n",
    "    if (row['target_name'] + '_' + str(row['dom#'])) in dl_full_uniqs:\n",
    "        dl30_int.loc[indy, 'int_size'] = 'full'\n",
    "    else:\n",
    "        dl30_int.loc[indy, 'int_size'] = 'mini'\n",
    "dl30_int        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_multi_hen_dict = {}\n",
    "for indy, row in dl30_int.iterrows():\n",
    "    if row['target_name'] in dl_multi_hen_dict.keys():\n",
    "        dl_multi_hen_dict.setdefault(\n",
    "            row['target_name'], []).append(row['int_size'])\n",
    "\n",
    "    else:\n",
    "        dl_multi_hen_dict[row['target_name']] = [row['int_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uri_multi int (later for mini inteins i think)\n",
    "dl_ds_gene_count = len(dl_inteins)  # number of total genes with 1+ inteins\n",
    "# multi_hens = 0 #skip but number of hens per multi genes\n",
    "dl_multi_inteins = 0  # multiple inteins total (count of inteins)\n",
    "# single intein in gene. if only 1 target_name (count of gene/inteins)\n",
    "dl_single = 0\n",
    "# single intein in gene w/HEN. (count of inteins) if only 1 target name and full\n",
    "dl_single_hen = 0\n",
    "# genes with multiple inteins (count of genes). if multiple target_names\n",
    "dl_multiple_genes = 0\n",
    "# multiple inteins with hen (count of inteins). if multiple target_names, and full\n",
    "dl_multiple_hen = 0\n",
    "# multiple_hen/multi_inteins = % of multiple inteins with HEN\n",
    "\n",
    "for target, vals in dl_multi_hen_dict.items():\n",
    "    if len(vals) == 1:\n",
    "        dl_single += 1\n",
    "        if vals[0] == 'full':\n",
    "            dl_single_hen += 1\n",
    "    if len(vals) > 1:\n",
    "\n",
    "        dl_multiple_genes += 1\n",
    "        dl_multi_inteins += len(vals)\n",
    "        for size in vals:\n",
    "            if size == 'full':\n",
    "                dl_multiple_hen += 1\n",
    "# need to change the flat values to be extensible\n",
    "print('Deep Lake\\nGenes with multiple inteins:\\t' + str(dl_multiple_genes) + ' (' + str(dl_ds_gene_count) + ')\\t' + str(dl_multiple_genes/dl_ds_gene_count) +\n",
    "      '\\nMulti-Inteins with HEN:\\t\\t' + str(dl_multiple_hen) + '\\t\\t' + str(dl_multiple_hen/dl_multi_inteins) +\n",
    "      '\\nSingle-Inteins with HEN:\\t' + str(dl_single_hen) + '\\t\\t' + str(dl_single_hen/dl_single) + \n",
    "     '\\nTotal full inteins:\\t\\t' + str(dl_single_hen + dl_multiple_hen) + ' (' + str(dl_single + dl_multi_inteins) + ')\\t' + str((dl_single_hen+dl_multiple_hen)/(dl_single + dl_multi_inteins)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl_nr_info = pd.read_csv('nr/dl_exteinbackground.tab', sep='\\t', header=None, usecols=[0, 3])\n",
    "dl_nr_info.columns = ['target_name', 'title']\n",
    "dl_nr_info.drop_duplicates(subset='target_name', inplace=True)\n",
    "dl_int_anno = dl30_int.merge(dl_nr_info, how='left', left_on='target_name', right_on='target_name')\n",
    "dl_int_anno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_int_anno['organism'] = dl_int_anno['title'].map(lambda x: re.search(r'\\[.+?(?=\\])|$', str(x)).group())\n",
    "dl_int_anno['gene'] = dl_int_anno['title'].map(lambda x: re.search(r'^.+?(?=\\[)|$', str(x)).group())\n",
    "dl_int_anno.drop(['title'], axis=1, inplace=True)\n",
    "dl_int_anno['organism'] = dl_int_anno['organism'].map(lambda x: x.lstrip('['))\n",
    "dl_int_anno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Lake Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, sites in dl_ext_sites.items():\n",
    "    site = 0\n",
    "    anchor = 0\n",
    "    if len(sites) > 2:\n",
    "        while site < (len(sites) -1):\n",
    "        \n",
    "            if site == 0:\n",
    "                anchor = anchor +  (sites[site] *3)\n",
    "                print(target + \"_ext:\" + str(anchor-3) + '-' + str(anchor+3) )\n",
    "                site += 2\n",
    "            if site % 2 == 0 and site != 0:\n",
    "                anchor = anchor + ((sites[site] - sites[site-1]) *3) \n",
    "                print(target + \"_ext:\"+ str(anchor-3) + '-' + str(anchor+3))\n",
    "                site +=2\n",
    "    else:\n",
    "        anchor = anchor +  (sites[site] *3)\n",
    "        print(target + \"_ext:\" + str(anchor-3) + '-' + str(anchor+3) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl_iis_sam = pd.read_table('../../DL30/hmmer/iis/shan/dl_final.sam',\n",
    "                        usecols=[0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13], header=None, sep='\\t')\n",
    "dl_iis_sam.columns = ['read', 'bits', 'target_name',\n",
    "                   'pos', 'mapq', 'cigar', 'mate_target', 'mpos', 'tlen' ,  'nm', 'as', 'xs']\n",
    "dl_iis_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_iis_counter = {}\n",
    "dl_iis_lens = {}\n",
    "#number  = 0\n",
    "for index, row in dl_iis_sam.iterrows():\n",
    "    if '3D' in row['cigar']:\n",
    "        \n",
    "        if row['target_name'][:-4] in dl_iis_counter.keys():\n",
    "            dl_iis_counter.setdefault(row['target_name'][:-4], []).append(row['cigar'])\n",
    "        else:\n",
    "            dl_iis_counter[row['target_name'][:-4]] = [row['cigar']]\n",
    "for target, vals in dl_iis_counter.items():\n",
    "    dl_iis_lens[target] = len(vals)\n",
    "dl_iis_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at22_int.description_of_target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_int_anno[at_int_anno['description_of_target'] == 'Bacteriophage T4-like capsid assembly protein (Gp20)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "772px",
    "left": "50px",
    "top": "101px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "836.85px",
    "left": "1483px",
    "right": "20px",
    "top": "37px",
    "width": "417px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
